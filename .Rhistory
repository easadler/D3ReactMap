train_factor$daypart[(train_factor$hour < 22) & (train_factor$hour > 15)] <- 3
test_factor$daypart[(test_factor$hour < 22) & (test_factor$hour > 15)] <- 3
#convert daypart to factor
train_factor$daypart <- as.factor(train_factor$daypart)
test_factor$daypart <- as.factor(test_factor$daypart)
#convert hour back to factor
train_factor$hour <- as.factor(train_factor$hour)
test_factor$hour <- as.factor(test_factor$hour)
#create our formula
formula <- count ~ season + holiday + weather + workingday  + temp + atemp + humidity + hour + daypart + sunday
#build our model
fit.ctree <- ctree(formula, data=train_factor)
#run model against test data set
predict.ctree <- predict(fit.ctree, test_factor)
#build a dataframe with our results
submit.ctree <- data.frame(datetime = test$datetime, count=predict.ctree)
#Find RMSLE
#rmsle(test_factor$count,predict.ctree)
#write results to .csv for submission
write.csv(submit.ctree, file="submit_ctree_v1.csv",row.names=FALSE)
View(submit.ctree)
fit.ctree
plot(fit.ctree)
cor(weather, temp)
names(train)
ctree_control(maxdepth = 100)
fit.ctree <- ctree(formula, data=train_factor)
fit.ctree
ctree_control(maxdepth = 10)
fit.ctree <- ctree(formula, data=train_factor)
plot(fit.ctree)
ctree_control(maxdepth = 1)
fit.ctree <- ctree(formula, data=train_factor)
plot(fit.ctree)
predict.ctree <- predict(fit.ctree, test_factor)
plot(predict.ctreee)
plot(predict.ctree)
stop
dfsd
seed(415)
train_original <- train_original[train_original$weather != 4,]
inTrain <- createDataPartition(train_original$count, p=0.7, list=F, times=1)
train <- train_original[inTrain, ]
test <- train_original[-inTrain, ]
#train <- train_original
#test <- test_original
#factorize training set
train_factor <- train
train_factor$weather <- as.factor(train$weather)
train_factor$holiday <- as.factor(train$holiday)
train_factor$workingday <- as.factor(train$workingday)
train_factor$season <- as.factor(train$season)
#factorize test set
test_factor <- test
test_factor$weather <- as.factor(test$weather)
test_factor$holiday <- as.factor(test$holiday)
test_factor$workingday <- as.factor(test$workingday)
test_factor$season <- as.factor(test$season)
#create time column by stripping out timestamp
train_factor$time <- substring(train$datetime,12,20)
test_factor$time <- substring(test$datetime,12,20)
#factorize new timestamp column
train_factor$time <- as.factor(train_factor$time)
test_factor$time <- as.factor(test_factor$time)
#create day of week column
train_factor$day <- weekdays(as.Date(train_factor$datetime))
train_factor$day <- as.factor(train_factor$day)
test_factor$day <- weekdays(as.Date(test_factor$datetime))
test_factor$day <- as.factor(test_factor$day)
aggregate(train_factor[,"count"],list(train_factor$day),mean)
#create Sunday variable
train_factor$sunday[train_factor$day == "Sunday"] <- "1"
train_factor$sunday[train_factor$day != "1"] <- "0"
test_factor$sunday[test_factor$day == "Sunday"] <- "1"
test_factor$sunday[test_factor$day != "1"] <- "0"
#convert to factor
train_factor$sunday <- as.factor(train_factor$sunday)
test_factor$sunday <- as.factor(test_factor$sunday)
#convert time and create $hour as integer to evaluate for daypart
train_factor$hour<- as.numeric(substr(train_factor$time,1,2))
test_factor$hour<- as.numeric(substr(test_factor$time,1,2))
#create daypart column, default to 4 to make things easier for ourselves
train_factor$daypart <- "4"
test_factor$daypart <- "4"
#4AM - 10AM = 1
train_factor$daypart[(train_factor$hour < 10) & (train_factor$hour > 3)] <- 1
test_factor$daypart[(test_factor$hour < 10) & (test_factor$hour > 3)] <- 1
#11AM - 3PM = 2
train_factor$daypart[(train_factor$hour < 16) & (train_factor$hour > 9)] <- 2
test_factor$daypart[(test_factor$hour < 16) & (test_factor$hour > 9)] <- 2
#4PM - 9PM = 3
train_factor$daypart[(train_factor$hour < 22) & (train_factor$hour > 15)] <- 3
test_factor$daypart[(test_factor$hour < 22) & (test_factor$hour > 15)] <- 3
#convert daypart to factor
train_factor$daypart <- as.factor(train_factor$daypart)
test_factor$daypart <- as.factor(test_factor$daypart)
#convert hour back to factor
train_factor$hour <- as.factor(train_factor$hour)
test_factor$hour <- as.factor(test_factor$hour)
#create our formula
formula <- count ~ season + holiday + weather + workingday  + temp + atemp + humidity + hour + daypart + sunday
#build our model
ctree_control(maxdepth = 0, mtry = 3)
fit.ctree <- ctree(formula, data=train_factor)
plot(fit.ctree)
#run model against test data set
predict.ctree <- predict(fit.ctree, test_factor)
#build a dataframe with our results
#submit.ctree <- data.frame(datetime = test$datetime, count=predict.ctree)
#Find RMSLE
rmsle(test_factor$count,predict.ctree)
#write results to .csv for submission
#write.csv(submit.ctree, file="submit_ctree_v1.csv",row.names=FALSE)
quit
setwd("/Users/evansadler/Desktop/OTA")
data.google <- read.csv("google-starttls-domains.csv", header = TRUE)
data.ota <- read.table("allwebsites", header = TRUE)
View(data.ota)
row.names(data.google) = NULL
data.google <- data.google[data.google$Fraction.Encrypted >= 0.5, (!names(data.google) %in% c('UN.M.49.Region.Code','Region.Name'))]
data.google <- data.google[data.google$Direction == 'inbound',]
data.google$Address.Suffix <- tolower(data.google$Address.Suffix)
data.ota$Website <- tolower(data.ota$Website)
TLS <- sapply(data.ota$Website, function(x){
if(length(unlist(strsplit(x, "\\."))) > 2) {
any(gsub('^[^.]+\\.', '', x) == data.google$Address.Suffix)
} else {
any( x == data.google$Address.Suffix)
}
}
)
TLS_Websites <- data.ota[TLS,]
TLS_Websites <- TLS_Websites[with(TLS_Websites, order(Sheet)), ]
write.table(TLS_Websites, file="outfile.txt", quote = FALSE, row.names = F)
data.google$Address.Suffix[data.google$Address.Suffix == 'norton.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'norton.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'google.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'lowes.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'lowes.com']
View(data.google)
data.google[data.google$Fraction.Encrypted == 1]
data.google[data.google$Fraction.Encrypted == 1,]
head(data.google[data.google$Fraction.Encrypted == 1,])
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'toysrus.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'shutterfly.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'fingerhut.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'cabelas.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'ruelala.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'Scholastic.com.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'Scholastic.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'scholastic.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'justfab.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'lego.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'levi.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'emusic.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'birchbox.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'petsmart.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'ritani.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'cbsnews.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'news.google.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'google.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'hindustantimes.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'hud.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'hud.gov']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'usps.gov']
data.google[data.google$Fraction.Encrypted == 1, data.google$Address.Suffix]
data.google[data.google$Fraction.Encrypted == 1, 'Address.Suffix']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'getpebble.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'capitalone.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == '53.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'unionbank.xom']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'unionbank.com']
data.google$Fraction.Encrypted[data.google$Address.Suffix == 'regions.com']
data.google <- read.csv("google-starttls-domains.csv", header = TRUE)
data.ota <- read.table("allwebsites", header = TRUE)
# Clean up google data
row.names(data.google) = NULL
data.google <- data.google[data.google$Fraction.Encrypted, (!names(data.google) %in% c('UN.M.49.Region.Code','Region.Name'))]
data.google <- data.google[data.google$Direction == 'inbound',]
data.google$Address.Suffix <- tolower(data.google$Address.Suffix)
hist(data.google$Fraction.Encrypted)
data.google <- read.csv("google-starttls-domains.csv", header = TRUE)
data.google <- data.google[data.google$Direction == 'inbound',]
hist(data.google)
hist(data.google$Fraction_Enycrpted)
hist(data.google$Fraction.Encrypted)
hist(data.google$Fraction.Encrypted, xLab="Fraction Encrypted", main="Google TLS Data")
hist(data.google$Fraction.Encrypted, freq=FALSE)
hist(data.google$Fraction.Encrypted, xLab="Fraction Encrypted", main="Google TLS Data")
hist(data.google$Fraction.Encrypted, xlab="Fraction Encrypted", main="Google TLS Data")
data.google$bins <- cut(data.google$Fraction.Encrypted, breaks= seq(0, 1.0, 0.1), right = TRUE, include.lowest = T)
data.freq <- count(data.google$bins)
require(plyr)
data.freq <- count(data.google$bins)
data.freq$perc <- data.freq$freq/sum(data.freq$freq)
View(data.freq)
barplot(data.freq$freq, space = 0.1, names.arg = data.freq$x, xlab="percent TLS", ylab = "sites", main="Distribution of Google TLS Data")
barplot(data.freq$perc, space = 0.1, names.arg = data.freq$x, xlab="percent TLS", ylab = "sites", main="Distribution of Google TLS Data")
percent <- data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 0]/nrow(data.google$Fraction.Encrypted)
percent
percent <- data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 0]/length(Fraction.Encrypted)
percent <- data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 0]/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 0])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 1])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted < 0.1])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 0])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 1])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted >= 0.5])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted < 0.5])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[data.google$Fraction.Encrypted == 0.5])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted > 0.6] & data.google$Fraction.Encrypted < 0.4])/length(data.google$Fraction.Encrypted)
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted > 0.6 & data.google$Fraction.Encrypted < 0.4])/length(data.google$Fraction.Encrypted)
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted > 0.6 & data.google$Fraction.Encrypted < 0.4)]/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted > 0.6 & data.google$Fraction.Encrypted < 0.4)])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted < 0.6 & data.google$Fraction.Encrypted > 0.4)])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted < 0.7 & data.google$Fraction.Encrypted > 0.3)])/length(data.google$Fraction.Encrypted)
percent
percent <- length(data.google$Fraction.Encrypted[which(data.google$Fraction.Encrypted < 0.9 & data.google$Fraction.Encrypted > 0.1)])/length(data.google$Fraction.Encrypted)
percent
nrows(data.google)
nrow(data.google)
sum(unique(data.google$Address.Suffix))
count(unique(data.google$Address.Suffix))
sum(count(unique(data.google$Address.Suffix)))
length(unique(data.google$Address.Suffix))
View(data.google)
package.install('dplyr')
install.packages('dplyr')
require(dplyer)
require(dplyr)
check <- data.google %>% count(Fraction.Encrypted, Address.Suffix) %>% filter(n == max(n))
View(check)
check <- data.google %>% count(Fraction.Encrypted, Address.Suffix) %>% filter(Fraction.Encrypted == max(Fraction.Encrypted))
View(check)
length(unique(check$Address.Suffix))
head(!unique(check$Address.Suffix))
head(unique(check$Address.Suffix))
tail(check)
View(check)
length(duplicated(check))
length(duplicated(check$Address.Suffix))
duplicated(check$Address.Suffix)
sum(duplicated(check$Address.Suffix))
check <- check %>% count(Fraction.Encrypted, Address.Suffix) %>% filter(Fraction.Encrypted == max(Fraction.Encrypted))
check <- data.google %>% group_by(Address.Suffix) %>% filter(Fraction.Encrypted == max(Fraction.Encrypted))
check <- data.google %>% group_by(Address.Suffix) %>% slice(Fraction.Encrypted == max(Fraction.Encrypted))
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
View(check)
View(check)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
View(check)
check <- data.google %>% group_by(Address.Suffix) %>% filter(Fraction.Encrypted = max(Fraction.Encrypted))
check <- data.google %>% group_by(Address.Suffix) %>% filter(Fraction.Encrypted == max(Fraction.Encrypted))
View(check)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
check <- data.google %.% group_by(Address.Suffix) %.% slice(max(Fraction.Encrypted))
check <- data.google %>% distinct(Address.Suffix) %>% slice(max(Fraction.Encrypted))
check <- data.google %>% distinct(Address.Suffix)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted)) %>% distinct(Address.Suffix)
View(check)
>
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
View(check)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted)) %>% distinct(Address.Suffix)
View(check)
check <- order(check$Fraction.Encrypted)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
check <- order(check$Fraction.Encrypted)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
check <- check[with(check, order(Fraction.Encrypted)), ]
View(check)
check <- check[with(check, order(-Fraction.Encrypted)), ]
View(check)
check <- check %>% distinct(Address.Suffix)
View(check)
check <- data.google %>% group_by(Address.Suffix) %>% slice(max(Fraction.Encrypted))
check <- check[with(check, order(-Fraction.Encrypted)), ]
View(check)
check[check$Address.Suffix == '7netshopping.jp',]
check <- check %>% distinct(Address.Suffix)
check[check$Address.Suffix == '7netshopping.jp',]
hist(check$Fraction.Encrypted, xlab="Fraction Encrypted", main="Google TLS Data")
check$bins <- cut(check$Fraction.Encrypted, breaks= seq(0, 1.0, 0.1), right = TRUE, include.lowest = T)
data.freq <- count(check$bins)
check$bins <- cut(check$Fraction.Encrypted, breaks= seq(0, 1.0, 0.1), right = TRUE, include.lowest = T)
data.freq <- count(check$bins)
View(check)
View(data.freq)
barplot(data.freq$perc, space = 0.1, names.arg = data.freq$x, xlab="percent TLS", ylab = "sites", main="Distribution of Google TLS Data")
percent <- length(check$Fraction.Encrypted[which(check$Fraction.Encrypted < 0.9 & check$Fraction.Encrypted > 0.1)])/length(check$Fraction.Encrypted)
percent
percent <- length(check$Fraction.Encrypted[check$Fraction.Encrypted == 1])/length(check$Fraction.Encrypted)
percent
length(check$Fraction.Encrypted[check$Fraction.Encrypted == 0])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted >= 0.5])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.5])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted < 0.5])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0])/length(check$Fraction.Encrypted)
data.google[data.google$Address.SUffix == 'twitter.com',]
data.google[data.google$Address.Suffix == 'twitter.com',]
data.google <- read.csv("google-starttls-domains.csv", header = TRUE)
row.names(data.google) = NULL
data.google <- data.google[data.google$Fraction.Encrypted, (!names(data.google) %in% c('UN.M.49.Region.Code','Region.Name'))]
data.google <- data.google[data.google$Direction == 'inbound',]
data.google$Address.Suffix <- tolower(data.google$Hostname.Suffix)
data.ota$Website <- tolower(data.ota$Website)
TLS <- sapply(data.ota$Website, function(x){
if(length(unlist(strsplit(x, "\\."))) > 2) {
any(gsub('^[^.]+\\.', '', x) == data.google$Address.Suffix)
} else {
any( x == data.google$Address.Suffix)
}
}
)
TLS_Websites <- data.ota[TLS,]
TLS_Websites <- TLS_Websites[with(TLS_Websites, order(Sheet)), ]
data.ota$Website <- tolower(data.ota$Website)
TLS <- sapply(data.ota$Website, function(x){
if(length(unlist(strsplit(x, "\\."))) > 2) {
any(gsub('^[^.]+\\.', '', x) == data.google$Hostname.Suffix)
} else {
any( x == data.google$Hostname.Suffix)
}
}
)
TLS_Websites <- data.ota[TLS,]
TLS_Websites <- TLS_Websites[with(TLS_Websites, order(Sheet)), ]
View(data.google)
data.google <- data.google[data.google$Fraction.Encrypted >= 0.5, (!names(data.google) %in% c('UN.M.49.Region.Code','Region.Name'))]
data.google <- read.csv("google-starttls-domains.csv", header = TRUE)
data.google <- data.google[data.google$Fraction.Encrypted >= 0.5, (!names(data.google) %in% c('UN.M.49.Region.Code','Region.Name'))]
data.google <- data.google[data.google$Direction == 'inbound',]
data.google$Hostname.Suffix <- tolower(data.google$Hostname.Suffix)
# Clean up OTA data
data.ota$Website <- tolower(data.ota$Website)
TLS <- sapply(data.ota$Website, function(x){
if(length(unlist(strsplit(x, "\\."))) > 2) {
any(gsub('^[^.]+\\.', '', x) == data.google$Hostname.Suffix)
} else {
any( x == data.google$Hostname.Suffix)
}
}
)
TLS_Websites <- data.ota[TLS,]
TLS_Websites <- TLS_Websites[with(TLS_Websites, order(Sheet)), ]
View(TLS_Websites)
data.google[data.google$Address.Suffix == 'usps.com']
data.google[data.google$Address.Suffix == 'usps.com',]
data.google[data.google$Address.Suffix == 'ally.com',]
length(check$Fraction.Encrypted[check$Fraction.Encrypted == 1])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.9])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.98])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.97])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.95])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.05 & check$Fraction.Encrypted < 0.95 ])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.00 & check$Fraction.Encrypted < 0.95 ])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.00 & check$Fraction.Encrypted < 0.90 ])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted > 0.00 & check$Fraction.Encrypted < 0.95 ])/length(check$Fraction.Encrypted)
length(check$Fraction.Encrypted[check$Fraction.Encrypted < 0.05])/length(check$Fraction.Encrypted)
getwd()
source('~/.active-rstudio-document', echo=TRUE)
setwd('/Users/evansadler/Desktop/Programming/')
setwd('/Users/evansadler/Desktop/Programming/react map')
print.files()
list.files()
data <- read.table('city_data.txt')
data <- read.table('city_data.txt')
data <- read.table('city_data.txt')
data <- read.table('city_data.txt')
data <- read.table('city_data.txt')
data <- read.table('city_data.txt')
data <- read.table('city_data.txt')
data <- read.table('data.csv', header = F)
data <- read.table('data.csv', header = F fill = T)
data <- read.table('data.csv', header = F, fill = T)
data <- read.table('data.csv', header = F, fill = T, as.is=T)
data <- read.table('data.csv', header = F, fill = T, as.is=F)
data <- read.table('data.csv')
data <- read.table('data.csv')
data <- read.csv('data.csv')
data <- read.csv('data.csv', stringsAsFactors=FALSE)
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
View(data)
data$X2013.land.area <- gsub("[^[:digit:]]", '', data$X2013.land.area)
View(data)
data$X2013.land.area <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.land.area))
data$X2013.land.area <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.population.density))
View(data)
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
# Remove units and commas/ convert to numeric
data$X2013.land.area <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.land.area))
data$X2013.population.density <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.population.density))
View(data)
require(plyr)
list <- strsplit(df$Location, " ")
list <- strsplit(data$Location, " ")
df <- ldply(list)
colnames(df) <- c("lon", "lat")
df <- ldply(list)
list <- strsplit(data$Location, " ")
df <- ldply(list)
list[1]
list[1][1]
list[1][1][1]
list[1][2]
list <- strsplit(data$Location, "N")
df <- ldply(list)
list <- as.vector(strsplit(data$Location, " "))
df <- ldply(list)
list <- str_split(data$Location, " ")
list <- unlist(strsplit(data$Location, " "))
list
packages.install('reshape2')
install.packages('reshape2')
library(reshape2)
library(reshape2)
colsplit(df$Location, ' ', names =  c('lon','lat'))
colsplit(df$Location, 'N', names =  c('lon','lat'))
data$Location <- as.character(data$Location)
colsplit(df$Location, ' ', names =  c('lon','lat'))
colsplit(df$Location, ' ', names =  c('lon','lat'))
data$Location <- as.numeric(gsub("[^[[:digit:]|[ \t\n\r\f\v]]", '', data$X2013.land.area))
View(data)
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
data$Location <- as.numeric(gsub("[^[[:digit:]|^[ \t\n\r\f\v]]", '', data$X2013.land.area))
data$Location <- as.numeric(gsub("[a-zA-Z]", '', data$X2013.land.area))
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
data$Location <- as.numeric(gsub("[a-zA-Z]", '', data$X2013.land.area))
data$Location <- as.numeric(gsub("[a-zA-Z]", '', data$Location))
View(data)
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
data$Location <- as.numeric(gsub("[a-zA-Z]", '', data$Location))
View(data)
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
data$Location <- gsub("[a-zA-Z]", '', data$Location)
View(data)
list <- strsplit(data$Location, " ")
df <- ldply(list)
colnames(df) <- c("lon", "lat")
colsplit(df$Location, ' ', names =  c('lon','lat'))
colsplit(data$Location, split = ' ')
colsplit(data$Location, split = " ")
colsplit(data$Location, split = "")
colsplit(data$Location, split = " ", names=c('a','b'))
matrix(unlist(list), ncol=2, byrow=TRUE)
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
# Remove units and commas/ convert to numeric
data$X2013.land.area <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.land.area))
data$X2013.population.density <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.population.density))
list <- strsplit(data$Location, " ")
df <- ldply(list)
colnames(df) <- c("lon", "lat")
View(data)
matrix(unlist(list), ncol=2, byrow=TRUE)
colnames(mat) <- c("lon", "lat")
mat <- matrix(unlist(list), ncol=2, byrow=TRUE)
colnames(mat) <- c("lon", "lat")
df<- as.data.frame(mat)
data <- cbind(data, df)
data <- na.omit(data)
data <- cbind(data, df)
View(data)
data$lon <- as.numeric(gsub("[^[:digit:]]", '', data$lat))
data <- cbind(data, df)
View(data)
setwd('/Users/evansadler/Desktop/Programming/react map')
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
data <- na.omit(data)
# Remove units and commas/ convert to numeric
data$X2013.land.area <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.land.area))
data$X2013.population.density <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.population.density))
# Split up Lat and Lon
list <- strsplit(data$Location, " ")
mat <- matrix(unlist(list), ncol=2, byrow=TRUE)
colnames(mat) <- c("lon", "lat")
df<- as.data.frame(mat)
data <- cbind(data, df)
# CLean Lat and Lon
data$lon <- as.numeric(gsub("[^[:digit:]]", '', data$lon))
setwd('/Users/evansadler/Desktop/Programming/react map')
data <- read.csv('data.csv', stringsAsFactors=FALSE, fileEncoding="latin1")
data <- na.omit(data)
# Remove units and commas/ convert to numeric
data$X2013.land.area <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.land.area))
data$X2013.population.density <- as.numeric(gsub("[^[:digit:]]", '', data$X2013.population.density))
# Split up Lat and Lon
list <- strsplit(data$Location, " ")
mat <- matrix(unlist(list), ncol=2, byrow=TRUE)
colnames(mat) <- c("lat", "lon")
df<- as.data.frame(mat)
data <- cbind(data, df)
# CLean Lat and Lon
data$lon <- as.numeric(-gsub("[^[:digit:]]", '', data$lon))
data$lat <- as.numeric(gsub("[^[:digit:]]", '', data$lat))
data$lon <- as.numeric(gsub("[^[:digit:]]", '', data$lon))
data$lon <- -data$lon
data$lat <- as.numeric(gsub("[^[:digit:]]", '', data$lat))
View(data)
data$City <- gsub("[^[:alpha:]]", '', data$City)
View(data)
